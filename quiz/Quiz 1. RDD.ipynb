{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the', 42)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Question 1 2 pts\n",
    "The following piece of code computes the frequencies of the words in a text file:\n",
    "\"\"\"\n",
    "from operator import add\n",
    "lines = sc.textFile('../data/README.md')\n",
    "counts = lines.flatMap(lambda x: x.split()) \\\n",
    "              .map(lambda x: (x, 1)) \\\n",
    "              .reduceByKey(add)\n",
    "\n",
    "# Add one line to find the most frequent word. Output this word and its frequency.\n",
    "counts.reduce(lambda x, y: y if x[1] < y[1] else x)\n",
    "# Hint: Use sortBy(), reduce(), or max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Welcome', 1),\n",
       " ('Spark', 10),\n",
       " ('documentation!', 1),\n",
       " ('readme', 1),\n",
       " ('navigating', 1),\n",
       " ('source', 3),\n",
       " ('code.', 1),\n",
       " ('documentation', 8),\n",
       " ('specific', 1),\n",
       " ('versions', 2),\n",
       " ('https://spark.apache.org/documentation.html.', 1),\n",
       " ('viewing', 1),\n",
       " ('yourself?', 1),\n",
       " ('correspond', 1),\n",
       " ('version', 6),\n",
       " ('revision', 2),\n",
       " ('Prerequisites', 1),\n",
       " ('tools', 1),\n",
       " ('Scala,', 2),\n",
       " ('Java,', 2),\n",
       " ('Python', 1),\n",
       " ('install', 4),\n",
       " ('following', 1),\n",
       " ('libraries:', 1),\n",
       " ('Pygments', 1),\n",
       " ('needed', 1),\n",
       " ('generating', 2),\n",
       " ('sphinx', 1),\n",
       " ('mkdocs', 1),\n",
       " ('\"devtools\",', 1),\n",
       " ('repos=\"http://cran.stat.ucla.edu/\")\\'', 3),\n",
       " ('Note:', 2),\n",
       " ('replace', 1),\n",
       " ('roxygen2', 2),\n",
       " ('SparkR', 3),\n",
       " ('generation', 1),\n",
       " ('field', 1),\n",
       " ('$SPARK_HOME/R/pkg/DESCRIPTION', 1),\n",
       " ('5.0.1,', 1),\n",
       " ('mismatched.', 1),\n",
       " ('Documentation', 2),\n",
       " ('include', 1),\n",
       " ('using', 6),\n",
       " ('definitive', 1),\n",
       " ('documentation)', 1),\n",
       " ('enable', 1),\n",
       " ('git).', 1),\n",
       " ('relevant', 1),\n",
       " ('regardless', 1),\n",
       " ('downloaded.', 1),\n",
       " ('directory', 4),\n",
       " ('files', 2),\n",
       " ('formatted', 1),\n",
       " ('Markdown,', 1),\n",
       " ('want.', 1),\n",
       " ('Start', 1),\n",
       " ('index.md.', 1),\n",
       " ('Execute', 1),\n",
       " ('compile', 1),\n",
       " ('site.', 1),\n",
       " ('Jekyll', 2),\n",
       " ('compiled', 1),\n",
       " ('default', 1),\n",
       " ('locally', 1),\n",
       " ('serve', 1),\n",
       " ('--watch', 1),\n",
       " ('Build', 1),\n",
       " ('PRODUCTION=1', 1),\n",
       " ('(Scaladoc,', 1),\n",
       " ('Sphinx,', 2),\n",
       " ('roxygen2,', 1),\n",
       " ('scaladoc', 3),\n",
       " ('build/sbt', 2),\n",
       " ('PySpark', 2),\n",
       " ('$SPARK_HOME/python/docs', 1),\n",
       " ('generated', 1),\n",
       " ('listed', 1),\n",
       " ('public', 1),\n",
       " ('$SPARK_HOME/R/create-docs.sh,', 1),\n",
       " ('after', 1),\n",
       " ('directory,', 1),\n",
       " ('directory).', 1),\n",
       " ('before', 1),\n",
       " ('generates', 2),\n",
       " ('Unidoc.', 1),\n",
       " ('MkDocs.', 1),\n",
       " ('NOTE:', 1),\n",
       " ('copying', 1),\n",
       " ('build.', 1),\n",
       " ('SKIP_PYTHONDOC=1,', 1),\n",
       " ('SKIP_RDOC=1', 1),\n",
       " ('SKIP_SQLDOC=1', 1),\n",
       " ('single', 1),\n",
       " ('docs.', 1),\n",
       " ('through', 1),\n",
       " ('building', 5),\n",
       " ('documentation,', 1),\n",
       " ('which', 3),\n",
       " ('included', 1),\n",
       " ('release', 2),\n",
       " ('learn', 1),\n",
       " ('about', 1),\n",
       " ('plain', 1),\n",
       " ('(i.e.,', 1),\n",
       " ('markdown)', 1),\n",
       " ('yourself.', 1),\n",
       " ('build', 11),\n",
       " ('whichever', 1),\n",
       " ('currently', 1),\n",
       " ('checked', 2),\n",
       " ('control.', 1),\n",
       " ('number', 1),\n",
       " ('Python,', 2),\n",
       " ('installed.', 1),\n",
       " ('jekyll', 10),\n",
       " ('jekyll-redirect-from', 1),\n",
       " ('pygments.rb', 1),\n",
       " ('Following', 1),\n",
       " ('pypandoc', 1),\n",
       " ('Rscript', 3),\n",
       " ('\\'install.packages(c(\"knitr\",', 1),\n",
       " ('\"rmarkdown\"),', 1),\n",
       " ('\\'devtools::install_version(\"roxygen2\",', 1),\n",
       " ('\"5.0.1\",', 1),\n",
       " ('\\'devtools::install_version(\"testthat\",', 1),\n",
       " ('\"1.0.2\",', 1),\n",
       " ('system', 1),\n",
       " ('gem2.0.', 1),\n",
       " ('Other', 1),\n",
       " ('might', 1),\n",
       " ('RoxygenNote', 1),\n",
       " ('updated', 1),\n",
       " ('Generating', 1),\n",
       " ('opposed', 1),\n",
       " ('hosted', 1),\n",
       " ('wiki,', 2),\n",
       " ('github', 1),\n",
       " ('evolve', 1),\n",
       " ('along', 1),\n",
       " ('captured', 1),\n",
       " ('control', 1),\n",
       " ('(currently', 1),\n",
       " ('automatically', 1),\n",
       " ('includes', 1),\n",
       " ('\".md\"', 1),\n",
       " ('suffix.', 1),\n",
       " ('those', 1),\n",
       " ('directly', 1),\n",
       " ('docs/', 1),\n",
       " ('Compiling', 1),\n",
       " ('create', 1),\n",
       " ('called', 1),\n",
       " ('_site', 2),\n",
       " ('containing', 1),\n",
       " ('index.html', 1),\n",
       " ('files.', 1),\n",
       " ('modify', 1),\n",
       " ('follows:', 1),\n",
       " ('(which', 1),\n",
       " ('takes', 1),\n",
       " ('while)', 1),\n",
       " ('SKIP_API=1', 2),\n",
       " ('Serve', 1),\n",
       " ('content', 1),\n",
       " ('extra', 1),\n",
       " ('features', 1),\n",
       " ('Javadoc,', 1),\n",
       " ('MkDocs)', 1),\n",
       " ('javadoc', 3),\n",
       " ('running', 4),\n",
       " ('unidoc', 2),\n",
       " ('$SPARK_HOME', 1),\n",
       " ('directory.', 2),\n",
       " ('Similarly,', 1),\n",
       " ('classes', 1),\n",
       " ('__init__.py.', 1),\n",
       " ('built', 2),\n",
       " ('$SPARK_HOME/sql/create-docs.sh', 1),\n",
       " ('first.', 1),\n",
       " ('various', 1),\n",
       " ('subprojects', 1),\n",
       " ('plugin', 2),\n",
       " (\"haven't\", 1),\n",
       " ('(recently)', 1),\n",
       " ('docs,', 1),\n",
       " ('addition,', 1),\n",
       " ('SKIP_SCALADOC=1,', 1),\n",
       " ('corresponding', 1),\n",
       " ('language.', 1),\n",
       " ('SKIP_SCALADOC', 1),\n",
       " ('indicates', 1),\n",
       " ('skipping', 1),\n",
       " ('Scala', 1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Question 2 2 pts\n",
    "Modify the word count example above\n",
    ", so that we only count the frequencies of those words consisting of 5 or more characters.\n",
    "\"\"\"\n",
    "counts = lines.flatMap(lambda x: x.split()) \\\n",
    "              .filter(lambda x: len(x) > 4) \\\n",
    "              .map(lambda x: (x, 1)) \\\n",
    "              .reduceByKey(add)\n",
    "counts.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Question 3 1 pts\n",
    "Consider the following piece of code:\n",
    "\"\"\"\n",
    "A = sc.parallelize(range(1, 100))\n",
    "t = 50\n",
    "B = A.filter(lambda x: x < t)\n",
    "print(B.count())\n",
    "t = 10\n",
    "C = B.filter(lambda x: x > t)\n",
    "print(C.count())\n",
    "\n",
    "# What's its output? (Yes, you can just run it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Question 4 2 pts\n",
    "The intent of the code above is to get all numbers below 50 from A and put them into B\n",
    ", and then get all numbers above 10 from B and put them into C.  \n",
    "Fix the code so that it produces the desired behavior, by adding one line of code.  \n",
    "You are not allowed to change the existing code.\n",
    "\"\"\"\n",
    "A = sc.parallelize(range(1, 100))\n",
    "t = 50\n",
    "B = A.filter(lambda x: x < t)\n",
    "\n",
    "# add this one\n",
    "B.cache()\n",
    "\n",
    "print(B.count())\n",
    "t = 10\n",
    "C = B.filter(lambda x: x > t)\n",
    "print(C.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Question 5 3 pts\n",
    "Modify the PMI example by sending a_dict and n_dict inside the closure. Do not use broadcast variables.\n",
    "\"\"\"\n",
    "lines = sc.textFile('../data/adj_noun_pairs.txt', 8)\n",
    "lines.count()\n",
    "lines.getNumPartitions()\n",
    "lines.take(5)\n",
    "# Converting lines into word pairs. \n",
    "# Data is dirty: some lines have more than 2 words, so filter them out.\n",
    "pairs = lines.map(lambda l: tuple(l.split())).filter(lambda p: len(p)==2)\n",
    "pairs.cache()\n",
    "pairs.take(5)\n",
    "N = pairs.count()\n",
    "N\n",
    "# Compute the frequency of each pair.\n",
    "# Ignore pairs that not frequent enough\n",
    "pair_freqs = pairs.map(lambda p: (p,1)).reduceByKey(lambda f1, f2: f1 + f2) \\\n",
    "                  .filter(lambda pf: pf[1] >= 100)\n",
    "pair_freqs.take(5)\n",
    "n_freqs.count()\n",
    "\n",
    "# use closure instead of Broadcasting the adjective and noun frequencies. \n",
    "n_dict = n_freqs.collectAsMap()\n",
    "a_dict = a_freqs.collectAsMap()\n",
    "a_dict['violent']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
