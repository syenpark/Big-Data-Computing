{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('./data/sales.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "df.createOrReplaceTempView(\"sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 Find all distinct countries.\n",
    "\n",
    "Hint: use select(), distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|      Country|\n",
      "+-------------+\n",
      "|       Sweden|\n",
      "|       Jersey|\n",
      "|     Malaysia|\n",
      "|       Turkey|\n",
      "|      Germany|\n",
      "|       France|\n",
      "|      Belgium|\n",
      "|      Finland|\n",
      "|United States|\n",
      "|        India|\n",
      "|       Kuwait|\n",
      "|        Malta|\n",
      "|        Italy|\n",
      "|       Norway|\n",
      "|        Spain|\n",
      "|      Denmark|\n",
      "|      Ireland|\n",
      "|       Israel|\n",
      "|      Iceland|\n",
      "|  South Korea|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Country\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|      Country|\n",
      "+-------------+\n",
      "|       Sweden|\n",
      "|       Jersey|\n",
      "|     Malaysia|\n",
      "|       Turkey|\n",
      "|      Germany|\n",
      "|       France|\n",
      "|      Belgium|\n",
      "|      Finland|\n",
      "|United States|\n",
      "|        India|\n",
      "|       Kuwait|\n",
      "|        Malta|\n",
      "|        Italy|\n",
      "|       Norway|\n",
      "|        Spain|\n",
      "|      Denmark|\n",
      "|      Ireland|\n",
      "|       Israel|\n",
      "|      Iceland|\n",
      "|  South Korea|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# should be same to this one\n",
    "distinct_countries = spark.sql(\"SELECT DISTINCT Country from sales\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 Find the Name and Price of sales records in Brazil.\n",
    "\n",
    "Hint: use filter()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 For each country, find the total Price.\n",
    "\n",
    "Hint: Use groupBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 List countries by their total Price in descending order.\n",
    "\n",
    "Hint: Use orderBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5 Now load a second table 'countries'\n",
    "http://www.cse.ust.hk/msbd5003/data/countries.csv \n",
    "\n",
    "df2 = spark.read.csv('countries.csv', header=True, inferSchema=True)\n",
    "Redo Question 3, but replace the country names by their IDs.\n",
    "\n",
    "Hint: Use join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 Rewrite the PageRank example using DataFrame API.  \n",
    "Here is a skeleton of the code.  Your job is to fill in the missing part.  The data files can be downloaded at:\n",
    "\n",
    "https://www.cse.ust.hk/msbd5003/data/pagerank_data.txt\n",
    "\n",
    "https://www.cse.ust.hk/msbd5003/data/dblp.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "numOfIterations = 10\n",
    "\n",
    "lines = spark.read.text(\"./data/pagerank_data.txt\")\n",
    "# You can also test your program on the follow larger data set:\n",
    "# lines = spark.read.text(\"dblp.in\")\n",
    "\n",
    "a = lines.select(split(lines[0],' '))\n",
    "links = a.select(a[0][0].alias('src'), a[0][1].alias('dst'))\n",
    "outdegrees = links.groupBy('src').count()\n",
    "ranks = outdegrees.select('src', lit(1).alias('rank'))\n",
    "\n",
    "for iteration in range(numOfIterations):\n",
    "# FILL IN THIS PART\n",
    "\n",
    "ranks.orderBy(desc('rank')).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: There is a bug in the current SparkSQL implementation: The groupBy (followed by some aggregation) method sometimes fails to group all rows with the same key.  A temporary workaround is the following:\n",
    "\n",
    "Suppose you want to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('A').sum('B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it fails to produce the desired result, try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumnRenamed('A', 'A1').groupBy('A1').sum('B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reported this bug to the Spark developers and the issue is currently under investigation:\n",
    "\n",
    "https://issues.apache.org/jira/browse/SPARK-20169 (Links to an external site.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
